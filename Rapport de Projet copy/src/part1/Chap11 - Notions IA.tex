\chapter{Concepts utiles d'Intelligence Artificielle}
    \section{Fonctionnement général du Machine Learning}

    \section{Algorithmes de classification}
        \subsection{Intérêt et fonctionnement de la classification}
        \subsection{Exemples d'algorithme de classification}
            \subsubsection{Régression logistique}
            \subsubsection{Bayésien naïf}
        \subsection{Métriques d'évaluation}
            \subsubsection{Matrices de confusion}
            \subsubsection{ROC et AUC}
            \subsubsection{Validation croisée à $k$-plis}
    \section{Deep Learning}
        Cette section s'appuie essentiellement sur \cite{UDL}.
        \subsection{Définition d'un réseau de neurones}
        \subsection{Hyperparamètres d'un réseau de neurones}
            \subsubsection{Taille du batch}
            \subsubsection{Taux d'apprentissage}
            \subsubsection{Nombre de couches cachées}
            \subsubsection{Taille des couches cachées}
            \subsubsection{Nombre d'échantillons}
        \subsection{Un modèle à deux réseaux : le \textit{Generative Adversarial Network} (GAN)}
            \begin{figure}[H]
                \centering
                \fbox{\input{figures/schemas/gan.tikz}}
                \caption{Schéma haut niveau d'un GAN}
            \end{figure}
    \section{Quelques métriques d'évaluation statistique}
        \subsection{Divergence de Kullback-Leibler}
        \subsection{Divergence de Jensen-Shannon}
