\chapter*{Annexe 1 : Programmes conçus par l'équipe}
\addcontentsline{toc}{chapter}{Annexe 1 : Programmes conçus par l'équipe}

L'ensemble des programmes est disponible sur le Github de l'équipe. Les principales fonctions
sont rappelées ici à titre informatif.
\begin{center}
    \url{https://github.com/ThomInsa/MIA-SnakeStrikesBack-INSA_CVL.git}
\end{center}

\begin{lstlisting}[caption={Fonctions permettant de classifier les fichiers \texttt{targetsTask}}]
from attackDopel import *

toClass1 = targets_Task1.drop(['Unnamed: 0', 'index'], axis=1)
toClass2 = targets_Task2.drop(['Unnamed: 0', 'index'], axis=1)
toClass3 = targets_Task3.drop(['Unnamed: 0', 'index'], axis=1)
toClass4 = targets_Task4.drop(['Unnamed: 0', 'index'], axis=1)

def export_TargetsClassification(pathToResultsFolder, taskNumber, classifiers_collection, predictions, title=""):
    separator = "\n------------------------------------------------------------------------------\n"
    resultDateTime = dt.datetime.today().strftime('%Y-%m-%d-%H-%M-%S')
    resultName = "results_Task" + str(taskNumber) + "_[" + resultDateTime + "].txt"
    resultPath = pathToResultsFolder + "Task " + str(taskNumber) + "/" + resultName
    resultTitle = title + "Results of classifiers for Task" + str(taskNumber) + "(" + resultDateTime + ")"
    resultsFile = open(resultPath, 'w')

    resultsFile.writelines(resultTitle)
    resultsFile.writelines(separator)

    modelIndex = 0
    for model in classifiers_collection:
        resultsFile.writelines(model.__class__.__name__ + " : \n-----\n")
        for i in range(len(predictions[modelIndex])):
            resultsFile.writelines(str(predictions[modelIndex][i]) + "\n")
        modelIndex += 1

    return 0

def classifyTarget(taskNumber, classifier_collection):
    predictions = []
    toClass = targetToClassifyFromInt(taskNumber)

    for model in classifier_collection:
        predictions.append(model.predict(toClass.values))
    return predictions

def targetToClassifyFromInt(taskNumber):
    match taskNumber:
        case 1:
            return toClass1
        case 2:
            return toClass2
        case 3:
            return toClass3
        case 4:
            return toClass4
        case _:
            return "Incorrect task number"
\end{lstlisting}

\newpage\begin{lstlisting}[caption={Fonctions permettant de créer et d'entraîner des classifieurs}]
import numpy as np
from sklearn import model_selection
from sklearn.dummy import DummyClassifier
from sklearn.linear_model import (
    LogisticRegression,
)
from sklearn.metrics import precision_score, confusion_matrix
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import (
    KNeighborsClassifier,
)
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.ensemble import (
    RandomForestClassifier,
)
import xgboost
from mlxtend.classifier import (
    StackingClassifier
)

import pandas as pd
import datetime as dt

def newClassifiersDatabase():
    classifiersDict = {'Classifier':[], 'Name':[], 'f1':[], 'precision':[], 'confusionMatrix':[], 'AUC':[], 'STD':[]}
    return pd.DataFrame(classifiersDict)

def trainModels(modelsToUse, X_train, y_train):
    classifiersCollection = []
    for model in modelsToUse:
        print("Training model : " + str(model.__name__))
        cls = model()
        cls.fit(X_train.values, y_train.values)
        classifiersCollection.append(cls)
    return classifiersCollection

def trainStackingClassifier(classifiersCollection, X_train, y_train):
    stack = StackingClassifier(
        classifiers=classifiersCollection,
        meta_classifier=LogisticRegression(),
    )
    print("Training model : StackingClassifier")
    stack.fit(X_train.values, y_train.values)
    return stack

def appendStackingClassifier(classifiersCollection, modelsCollection, X_train, y_train):
    stack = StackingClassifier(
        classifiers=classifiersCollection,
        meta_classifier=LogisticRegression(),
    )
    modelsCollection.append(stack)
    stack.fit(X_train.values, y_train.values)
    classifiersCollection.append(stack)
    return classifiersCollection

def createCollection_Predictions(classifiersCollection, X_test):
    predictionsCollection = []
    for model in classifiersCollection:
        prediction = pd.DataFrame(model.predict(X_test))
        prediction.rename(columns={"0": "isMember"})
        predictionsCollection.append(prediction)
    return predictionsCollection

def createCollection_PrecisionScore(y_test, predictionsCollection):
    precisionCollection = []
    index = 0
    for prediction in predictionsCollection:
        precisionCollection.append(precision_score(y_test.values, predictionsCollection[index]))
        index += 1
    return precisionCollection

def createCollection_ROC(classifiersCollection, X, y, X_train, y_train, value = "mean"):
    rocCollection = []
    index = 0
    for classifier in classifiersCollection:
        s = model_selection.cross_val_score(classifier, X, y, scoring='roc_auc', cv=model_selection.KFold(n_splits=10, random_state=42, shuffle=True))
        if value == "mean":
            rocCollection.append(s.mean())
        elif value == "std":
            rocCollection.append(s.std())
        else:
            print("Invalid value, choose mean or std for ROC computation")
            return 1
        index += 1
    return rocCollection

def createCollection_ConfusionMatrices(y_test, predictionsCollection):
    matricesCollection = []
    for prediction in predictionsCollection:
        matrix = confusion_matrix(y_test, prediction)
        matrix = np.round(matrix / len(prediction), decimals=2)
        matricesCollection.append(matrix)
    return matricesCollection

def createClassifiersMetricsDB(classifiersCollection, X, y, precisionsCollection, matricesCollection, ROCMCollection, ROCSCollection):
    classifiersDB = newClassifiersDatabase()
    index = 0
    for classifier in classifiersCollection:
        newRow = (classifier , classifier.__class__.__name__, classifier.score(X,y), precisionsCollection[index], str((matricesCollection[index]).tolist()), ROCMCollection[index], ROCSCollection[index])
        classifiersDB.loc[len(classifiersDB)] = newRow
        index += 1
    return classifiersDB

def saveClassifiersMetricsDB(classifiersDB, directory_path, file_name):
    now = dt.datetime.today().strftime('%Y-%m-%d-%H-%M-%S')
    new_file_name = file_name + f"classifiersPerfs_{now}.csv"
    file_path = f"{directory_path}{new_file_name}"
    (classifiersDB.drop(columns=['Classifier'])).to_csv(file_path, index=False)
\end{lstlisting}

\newpage\begin{lstlisting}[caption={Fonctions permettant de créer les données d'entraînement des
classifieurs}]
import os
import pandas as pd

from data.teamExperiments.attackDopel import npzPrivateToDataframe, publicData_Tasks12, publicData_Tasks34

def createFinalTrainingSet(nonMembersPart, membersPart):
    addMembershipToSubset(nonMembersPart, 0)
    addMembershipToSubset(membersPart, 1)
    trainingSet = pd.concat([nonMembersPart, membersPart])
    return trainingSet

def makeMemberPart(privateDataset_Path, clean = False):
    members_clean = pd.DataFrame()
    members_unclean = pd.DataFrame()
    setToExclude = []
    for file in os.listdir(privateDataset_Path):
        # print(file)
        if file.endswith(".npz"):
            members_unclean = pd.concat([members_unclean, npzPrivateToDataframe(os.path.join(privateDataset_Path, file))], ignore_index=True)
            if file not in setToExclude:
                members_clean = pd.concat([members_clean, npzPrivateToDataframe(os.path.join(privateDataset_Path, file))], ignore_index=True)
    if clean:
        return members_clean
    else:
        return members_unclean


def makeNonMemberPart(memberPart, taskNumber):
    nonMembers = pd.DataFrame()
    if taskNumber == 1 or taskNumber == 2:
        allNonMembers = pd.concat([publicData_Tasks12, memberPart, memberPart]).drop_duplicates(keep=False)
    elif taskNumber == 3 or taskNumber == 4:
        allNonMembers = pd.concat([publicData_Tasks34, memberPart, memberPart]).drop_duplicates(keep=False)
    else:
        print("Task number not recognized")
        return 1
    while len(nonMembers) < len(memberPart):
        rowToAdd = allNonMembers.sample()
        nonMembers = pd.concat([nonMembers, rowToAdd])
    return nonMembers

def makeSubsetFromDataset(dataFrame, subsetStartIndex, subsetEndIndex_excluded):
    # Make small datasets from the original dataset
    return dataFrame.iloc[subsetStartIndex:subsetEndIndex_excluded].copy()

def addMembershipToSubset(subset, isMember):
    newSubset = subset.copy()
    if isMember == 0 or isMember == 1:
        subset["isMember"] = isMember
        return newSubset
    else:
        print("Second parameter must be 0 or 1. Your dataset hasn't changed")
        return newSubset
\end{lstlisting}


